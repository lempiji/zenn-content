---
title: "Codexでスキマ時間開発：D言語静的解析ツール similarity-d を作るまで"
emoji: "⏳"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["dlang", "ai", "openai", "codex", "tdd", "静的解析", "ツール"]
published: true
---

## はじめに
こちらは、D言語 Advent Calendar 2025 7日目の記事となります。

https://qiita.com/advent-calendar/2025/dlang

今回は、D言語製のコード類似度解析ツール `similarity-d` を **OpenAI Codex を使って、ほぼスマホだけ & スキマ時間で開発した** 経験談を共有します。

- AI を使った開発がどんな感じか知りたい方
- Codex の具体的な設定例を「とりあえず動くリファレンス」として見たい方
- 「実際にツールを作りきった事例」を知りたい方

あたりの参考になればうれしいです。
（タイトル回収としては「作れたよ！」ってことです）


以下、内容に入っていきます。

### 前置き

- この記事で話すこと
    - OpenAI Codexを使ってD言語の静的解析ツールを開発した経験談、実績値
    - 開発スタイル、うまくいったこと・いかなかったこと
    - こうやれば多分真似できる設定等（2025年12月時点）
- この記事で話さないこと
    - similarity-d のアルゴリズムの詳細解説（機会があれば別記事で）
    - D言語の基礎知識（[色々あります](https://qiita.com/search?sort=&q=tag%3Adlang)）
    - OpenAI Codexの基礎知識（最新の記事だと [このあたり](https://zenn.dev/okdyy75/articles/lets-try-using-codex-cloud) が参考になります）

## similarity-d のざっくり紹介

- D言語製の **コード類似度** 解析ツール
  - 関数単位でソースコードを解析し、類似度の高い関数のペアを検出
- コードレビュー支援やリファクタリング支援に利用可能
- D言語のコンパイラ機能（dmd）をライブラリとして使い、ASTの構文レベルで類似度（ツリー編集距離）を算出
  - Visitor使うとか興味がある方はリポジトリ参照してください

__GitHub リポジトリ__

https://github.com/lempiji/similarity-d

__Dubパッケージ（dub runで実行可能）__

https://code.dlang.org/packages/similarity-d

## 開発経緯

- 開発動機は、 [mizchi](https://x.com/mizchi) 氏が Claude Code で [mizchi/similarity](https://github.com/mizchi/similarity) を作っていたのを見て、前から作ってみようと思っていたツールだったから勢いでやりました
  - 元ソースほぼ読んでないので、ツリーベースの編集距離でやるコンセプトだけ真似た、というのが正しいかも
- 元々Codexは使っていて、D言語書けることも知っていたので「いけるやろ」の気持ちになりました。

## 開発スタイル

- OpenAIのPlusプラン加入済み
- ほぼ ChatGPT + OpenAI Codex（Webマネージド版）だけで開発
  - ChatGPTは、セットアップスクリプト書いてもらうとか、開発フローの決め事洗い出しに使いました
  - Codexは、実装、テスト追加、ドキュメント追加、GitHub Actions追加などすべての開発作業に使いました
- 操作した端末はほぼスマホ1つ
  - 最後に動作確認でローカルのVSCode触りましたが、それまではゼロです。何かが終わってしまった感がある。
- 開発のタイミングは、主に通勤や寝る前、諸々の家事のスキマ時間
  - スキマ時間でCodexに指示しておき、スキマ時間で終わったかチェックし、スキマ時間で内容レビューしてPR作成→マージ、を繰り返しました
  - 具体的な作業の流れとかは後述します

## 開発統計

最初にCodex使って3日くらいでガッと形を作ったものの、リポジトリ名変更等でリポジトリ再作成したので残念ながら序盤のログがありません。
（first commitの時点ですでに結構なコードがコミットされてます）

以下の数字は「作り直したあとのリポジトリ」だけを見たものなので、実際の全体像はそれぞれ「+α」されていると思ってください。
ざっくりの補正としては、開発期間 +3日、コミット数 +30、CodexのPRマージ数 +20くらいです。

- 最終ソースコード行数: 825行 (source以下を集計、[計測方法](https://qiita.com/lempiji/items/67489eb2da3c54031ba6))
- リポジトリの開発期間: 15日間 (2025-06-29 から 2025-07-13)
- うちCommitがあった日数: 9日間
- 総Commit数: 153
- うちCodexによるPRマージ数: 84（約63%）
- 1日最多Commit数: 59（2025-07-06） 

### 補足

ログがない体感レベルの情報の補足です。

全体で恐らく18日くらいで作っていますが、「スキマ時間で開発」が裏テーマだったので実働というか拘束時間ははるかに少ないです。

1日の中で開発作業（主にCodexポチポチしてた時間）は、平日で平均1時間いかないくらい、休みの日で最大3時間くらいです。
コミットログ的にまったく触ってない日が6日くらいあること踏まえると、**実質作業時間は合計26時間くらい** になると思います。

これはもちろん全部手で作るよりは短い時間ですが、あくまでも「作業に必要な拘束時間」であって「作業リードタイム」（着手～完了までの時間）ではありません。
要するにCodexの作業待ち時間（1タスク2～15分くらい）があるので、待つときは結構待ちます。1回のスキマ時間で指示は1回しか出せない、という感じでした。
恐らくですが、 **詰め込んでも4日かそれ以上** はかかりそうです。

また、割合としては開発20%、テスト75%、リリース5%、くらいと思います。
テストの3割くらいは考えたりする時間です。

圧倒的にテスト追加にかけた時間が多く、それで実装不足を見つけては直すのを繰り返すことになります。
手数で何とかする方針にしたものの、これはこれで大変でした。


## 準備編

以下、開発を始めるための準備です。
真似してもらえればCodexでD言語プロジェクトを開発できるようになるはずです。

今回の開発に限りませんが、Codexを使う開発では着手する前に2つ準備をします。

1. Codexの環境準備
2. 開発のための指示（AGENTS.md）

### Codexの環境準備

Codexは例によりサンドボックス環境でリポジトリをクローンしてきて動きます。

動かすには、GitHubリポジトリを作っておき、Codexの環境設定でいくつかの設定項目を入力する必要があります。
プライベートリポジトリでも良いです。

`similarity-d`の場合、空のリポジトリを作っておき、以下のように設定しました。
たまに設定画面見ると項目変わったり増えたりしているので、適宜読み替えてください。

1. リポジトリ: similarity-d（GitHub連携して権限を与えておけば、今回作成したリポジトリを選択するだけ）
2. 名前: lempiji/similarity-d（リポジトリ名が勝手に入るので大体そのまま）
3. 説明: 空（任意）
4. コンテナイメージ: universal（既定値）
5. 環境変数: なし
6. シークレット: なし（セットアップ時のみ有効らしいが、極力避けた方が良さそう）
7. コンテナのキャッシュ: 有効（セットアップに時間が掛かる場合は特に有効）
8. セットアップスクリプト: 手動（内容後述、メンテナンススクリプトは空にしました）
9. エージェントのインターネットアクセス: 有効（主に外部リポジトリ参照と依存関係更新のため）
  - ドメイン許可リスト: 共通の依存関係
  - 許可対象の追加ドメイン: `dlang.org`
  - 許可されているHTTPメソッド: すべてのメソッド

で、具体的には以下のセットアップスクリプトを設定して完了です。
入れたのは `dmd` と `dub`、コードフォーマッター兼Linterの `dfmt` です。（しかし今回`dfmt`は使ってないです）
多分ローカルインストールにも転用できますが、その場合は恐らく [人生最良の行動](https://zenn.dev/outlandkarasu/articles/ceeb5f31cbd543) を参考としてもらった方が良いです。

```bash
##!/usr/bin/env bash
set -euo pipefail

INSTALL_DIR="/workspace/dlang"
INSTALL_SH="${INSTALL_DIR}/install.sh"

mkdir -p "${INSTALL_DIR}"

if command -v curl >/dev/null 2>&1; then
    curl -fsSL https://dlang.org/install.sh -o "${INSTALL_SH}"
elif command -v wget >/dev/null 2>&1; then
    wget -qO "${INSTALL_SH}" https://dlang.org/install.sh
else
    echo "Error: Please install curl or wget." >&2
    exit 1
fi

chmod +x "${INSTALL_SH}"

"${INSTALL_SH}" install dmd,dub

ACTIVATE_PATH="$("${INSTALL_SH}" dmd -a)"

RCFILE="${HOME}/.bashrc"
if ! grep -Fxq "source ${ACTIVATE_PATH}" "${RCFILE}"; then
    echo '' >> "${RCFILE}"
    echo "# Auto-activate D environment" >> "${RCFILE}"
    echo "source ${ACTIVATE_PATH}" >> "${RCFILE}"
fi

source "${ACTIVATE_PATH}"

dub fetch dfmt

echo "DMD version: $(dmd --version)"
echo "DUB version: $(dub --version)"
echo "Installation and setup complete."
```

### 開発のための指示（AGENTS.md）

Codexに開発手順を指示するためのドキュメント `AGENTS.md` をリポジトリルートに用意します。
無くてもなんとか動くと思いますが、あると劇的に効率が良くなります。

指示することは大きく2つです。

- プロジェクトの文脈
  - 「どういうことをするための何なのか」「どうやって動くべきなのか（設計思想）」
  - README.mdで代替できればそんなに書かなくて良さそう
- 開発手順
  - ビルドやテストのコマンド、ディレクトリ構成、設計書の管理
  - できればコミットルールや運用ルールも

英語で書いてますが、これもほとんどChatGPTとCodexに書いてもらいました。
セットアップスクリプトで構築は済んでいるので、「/workspace/dlang/install.shとdmd/dub/dfmtのコマンドを確認して、手順としてまとめてAGENTS.mdに書き足して」という指示を出した感じです。
あとは細かい開発用ルールをChatGPTにざっくり決めてもらい、Codex向けプロンプトを書かせて、それを流し込んでCodexに書かせました。（流石に手編集で良かったかも）

これに加えて[ドキュメント管理向けのAGENTS.md](https://github.com/lempiji/similarity-d/blob/main/docs/design/AGENTS.md)も用意しています。
ディレクトリ毎に分ければ、それ以下のディレクトリを触るときに考慮してくれるらしいです。

ルートのほうだけ全文載せておきます。細かいところ興味があれば読んでみてください。
カバレッジ取るところまで書いてますが、割と最小限に近い構成としているつもりです。

~~~markdown
## AGENTS.md

This repository contains `similarity-d`, a CLI tool and library for detecting similar D functions. It relies on the DMD front-end to parse source files and a custom tree edit distance implementation.

### Setup

- Use `dmd` **2.111.0** or newer and ensure `dub` is on your `PATH`.
- If the compiler is missing, run the installer script located at `/workspace/dlang/install.sh`.
- After installation run `dub --version` to verify the tool chain is accessible.

### Testing

The project includes extensive unit tests. Always run them before committing:

```bash
dub test --coverage --coverage-ctfe
```

- The command generates `source-*.lst` coverage files. Check the final two lines of each file to confirm the percentage is **70% or higher**.
- If overall coverage drops below the threshold, add tests to raise it before merging.
- Old coverage files can be removed with `dub clean` when necessary.

After tests pass, ensure the CLI still functions with a minimal invocation:

```bash
dub run -- --dir source/lib --exclude-unittests --threshold=0.9 --min-lines=3
```

### Design Documents

- Architectural decisions and feature proposals live in `docs/design/`.
- Follow the workflow defined in `docs/design/AGENTS.md` for creating **Proposals** and **ADRs**.
- Do not start coding until a Proposal is **Approved** and any related ADR is **Accepted**.

### Code Overview

```
source/cli        entry point and command-line options
source/lib        core library modules
  ├─ functioncollector.d  – parse files and extract functions
  ├─ treediff.d           – normalize ASTs and compute similarity
  ├─ treedistance.d       – basic tree edit distance algorithm
  └─ crossreport.d        – high level matching and reporting utilities
```

The CLI (`source/cli/main.d`) wires these pieces together. Tests for each module reside at the bottom of the corresponding `.d` file.

### Contribution Workflow

1. Create or update design docs under `docs/design/` when planning new features.
2. Open a PR referencing the Proposal/ADR IDs once they are approved.
3. Run tests and verify coverage before pushing.
4. Keep README and documentation up to date when behavior changes.
5. Use clear commit messages explaining *why* a change is made.

Following these guidelines keeps the codebase maintainable and ensures design decisions remain traceable.

### Dependency Maintenance (DUB)

Periodically refresh DUB dependencies while keeping the workflow simple.

1. Run `dub upgrade` in the repository root. This updates `dub.selections.json` to the latest versions permitted by `dub.json` or `dub.sdl`.
2. When a newer major version is desired, run `dub add <package>` to change the version range, then repeat `dub upgrade`.
3. Execute the tests:
   ```bash
   dub test --coverage --coverage-ctfe
   ```
   Ensure every `source-*.lst` file ends with **70%** coverage or higher.
4. Verify the CLI still works:
   ```bash
   dub run -- --dir source/lib --exclude-unittests --threshold=0.9 --min-lines=3
   ```
5. Commit the updated `dub.selections.json` and any modified manifest files. Document major version bumps when behaviour changes.

This workflow keeps dependencies current while ensuring upgrades do not break existing functionality.
~~~

## 開発プロセス

というわけでやったこと掘り下げていきます。
おおまかにやった順で整理します。

### 1. リポジトリ初期化

Codexに雑に指示して上手くいった部分です。
「D言語の `dub` プロジェクトとして現在のリポジトリを初期化して」という指示で一発作成でした。

Codexは `dub init` の理解もあり、依存関係に `dmd` を追加するのもできました。
ただ動作を見る限り、依存追加は知らないコマンド勘で叩いてエラーになったらヘルプを見る、という感じでした。
npmっぽいサブコマンドを使いたそうに見えました。まぁ、わかります。

ここでビルドするついでに GitHub Actions のセットアップとREADMEにバッジをつけるところまでやってもらいました。

ログを見るとなんか随分あっさりついてますが、指示する時に **「[既存のリポジトリ](https://github.com/lempiji/openai-d)のCIを参考にして書いて」と指示する** のがポイントです。
**指示しないとビルドキャッシュとかちゃんと書けません。**（お察し）

確かこの時の作業では、指示したリポジトリを即座にcloneしてきてファイル確認するような動きをしており、そのスマートさに感動しました。
サンドボックスはリポジトリ専用の何かだと思い込んでいたので、すごかったです。（語彙）


### 2. 基本機能をREADMEに書く（ChatGPT作業）

ChatGPTでThinkingモードを使って最初にREADMEを粗方書いてもらい、そこから話を進めるようにしました。
ひとまずやりたいことと使い方を書いたドキュメントが一本あれば、それに沿って実現していくだけなので開発がブレにくくなります。

作業自体はGitHubのWeb UIから直接編集して貼り付けてます。
ChatGPTが更新してくれてもいいのになぁと思いつつ、Codexの出番なし。

ちなみに私は「READMEなんてなんぼ長くても良いですからね」と思ってる派です。
今回はCodexに色々サンプル動作について追記してもらいましたが、[手動で一通り書く](https://github.com/lempiji/golem) というのもオススメです。
Markdownのサンプルコードは [そのまま実行できてテストになる](https://github.com/lempiji/md) ので書いたら書いただけ良いです。
雑な宣伝でした。


### 3. 実装としてTDDを回し続ける

AI使って開発することについてはあちこちで色々言われていますが、やることは基本すべてテスト駆動、TDDとしました。

D言語らしく `unittest` ブロックを書いてもらい、 実装して、`dub test` を回してもらう、を繰り返しました。
`dub test` はAGENTS.mdに書いてあるので指示毎に毎回確実に実行してくれます。えらい。

具体的な指示方法は後述しますが、あんまり手間を掛けずに数で何とかする方向でやりました。


#### 毎回の差分レビューのポイント

コミット前に必ず差分レビューするようにしていましたが、レビューが大変なのはわかっているので、あえてかなり手を抜きました。
結果、レビュー自体はそんなに大変ではなかったなぁ、という印象です。

今回レビューはたった1つ重要なこととして **「マージしても安全か？」基準** でやりました。
具体的には以下のポイントをチェックしました。

1. 意図しない範囲のコードを修正してないか？消していないか？
   - 現在のタスク指示をコンテキストとして持っていないと判断に困る内容は即時チェック対象
2. テストを変に変えていないか？
   - 割合として低くても、モデルの変な動きは結局人間がガードレールにならないとダメそうだったので

逆に言えば、以下の点は見ないで後でカバーすればいいや、という感じです。

1. コードやドキュメントの品質、スタイル
   - たとえばコードの統一感、命名規則、コメントの有無など、「後で見ても問題に気付けるし直せる」範囲。
2. アルゴリズムの最適化
   - 指示一発で完璧を目指すと終わらないので、全体通して徐々に改善していく方針


### 4. 設計ドキュメントをCodexに書かせつつ機能強化

開発中盤で1日やってみたものの、あんまりうまくいかなかったのがこの辺りです。

開発が進んできて「ローカル関数（ネストした関数）」の存在を思い出してどうしようかと悩んだ時、「せっかくだから設計→実装をやっておこう」と思い立ってドキュメント書かせました。

ドキュメントの管理手法は [自作の別プロジェクト](https://github.com/lempiji/openai-d/tree/main/docs/design) からの流用です。
これ自体別に上手くいっている管理手法ではないのですが、とりあえず作ったからやってみよう、ということで使いました。

管理の内容は、ある設計に至った理由を記録する「ADR」（Architectural Decision Record）と、機能追加の動機や方針を記録する「Proposal」の2本立てです。
いくつかのリポジトリを漁りつつソフトウェア開発のよくあるテンプレにならって、それらしきことをやろうとしましたが、結果は伴わず。

[書かれた結果](https://github.com/lempiji/similarity-d/blob/main/docs/design/proposals/0001-nested-function-collection.ja.md) を見てみると、単に「内容が薄い」のであんまり役に立ちませんでした。
また、進めてみると直接実装指示するだけで特に問題なく、小規模ツールなのに変な寄り道をしてしまった、という感じです。
ChatGPTに書かせたらもう少しマシだったかもしれません。


### 5. リリース準備

ここはCodex+手動でやりました。
やったことは、ローカルで動作確認、CodexにCHANGELOG.md用意してもらい、調整してGitHubでリリース、です。

その気になればリリース作業も任せられると思いますが、DUBに公開しているのもあって怖いから手でやりました。
また動作確認だけはローカル環境での実施が外せませんでした。仕方なし。

CHANGELOG.mdはCodexに「過去のコミットログを参考にしてCHANGELOG.mdを書いて」という指示で書いてもらいました。
しかしこのあたり、何を思ったか結果をChatGPTに校正させたので手動コミットになってしまっています。
変なアウトラインになっていたのを直したみたいですが、ソースコード以外は本当に苦手なのかもしれません。


## タスク指示

ここから具体的な指示出しの部分を振り返ります。
今回のスタイルをざっくり言うと、「何をやるにもプランモードでタスクを提案させて、複数案を並列で走らせて一番マシなものを採用する」です。

### プランモードでタスクを提案させる

プランモードというのは、コードの編集機能とかをそぎ落として、読み取り専用で素早く実行するモードだそうです。
これを使うと、コードの編集が必要ない「リポジトリ構造説明して」みたいな依頼が効率的に処理できます。

Codexにはもう1つ面白い機能があり、それが「タスク提案機能」です。
例えば「～～のためのタスクを提案して（作成して）」という指示を出すと、CodexがAGENTS.mdを参照しつつ「必要と思われるタスク」を提案してくれる機能です。

今はわかりませんが、私が触り始めた時は環境作ると以下のタスク指示がポンと呼び出せるようになっていました。

```
コードベースの概要を確認し、問題を見つけて、入力ミスを修正するタスク 1 件、バグを修正するタスク 1 件、コードのコメントまたはドキュメントの矛盾を修正するタスク 1 件、テストを改善するタスク 1 件を提案してください。
```

これを初めて見た時は非常に感心しました。
表現こそマイルドですが、とりあえず改善しそうなことを無限にやらせるブラック魔法の詠唱呪文に見えます。空のリポジトリだったらどうするんでしょうね？

とまぁこれを参考に、 **「（目的）のために、現在のコードベースを確認して、実現するためのタスクを1～3件提案してください」** という指示を出し、出てきたタスクを1つずつ実行していく、というスタイルで指示出ししてました。

なお、**実際3個出てきても同時実行すると競合しそうなものは実行を避け、手で弾く** ようにしていました。
理由は、**コンフリクトするとGitHubのWeb UIをスマホで触るのでめっちゃ面倒** だからです。スキマ時間にやることではない。
脳内で開発工程シミュレーションする能力が求められます。


### 並列で複数案を走らせて「一番良さそうなもの」を採用する

私は勝手に「投機的実行」と呼んでいるんですが、いかにも富豪的なAIの使い方をしてしまったので紹介します。
ご利用は計画的に。

まず前提として現代のLLMは初期値の入力に乱数を取れるのですが、これによって意図的に「同じ指示を出しても違う振舞いをする（違う実装になる）」という状況が作れます。
最善になるシードがあれば固定で良いのかもしれませんが、Codex含む現実問題としてほとんどの場合でそんなシード値は不明です。（なお [反例らしきもの](https://arxiv.org/abs/2109.08203)）

Codexもそれを踏まえて、「1つの指示に対して最大4並列で実行させる」という機能があります。
つまり **「複数実行して違う結果が得られたら、その中で一番良いもの1個だけ採用すればいいじゃない」** ということです。
言い換えると、とりあえず色々試して上手くいったところを残して、 **余計なところは捨ててしまう** 、ということでもあります。
この構図が、CPUの「投機的実行」（分岐予測先を先に計算しておきヒットしなければ捨てる）と同じように見えるので、私はこれを「投機的実行」と呼んでいます。


さて、先のタスク提案を踏まえると、指示出しの構図としては「タスクの提案ステップ」と「実際のタスク実行ステップ」で2段階あります。
この並列実行をタスク実行ステップだけに適用しても良いのですが、それだと多様性が限られる印象でした。
そこで提案ステップにも並列実行を適用して **両方で並列実行する** ことで、「解（実装）の多様性を持たせてより良い実装を得る」という効果を狙いました。
指示出しも雑にできて一石二鳥。もう一段くらいメタにできそうですが、すでに結構手間なのでやってません。

というわけでやるのは以下です。

1. タスク提案ステップ
    - 「（目的）のために、現在のコードベースを分析して、実現するためのタスクを1～3件提案して」という指示を4並列で実行
    - 出てきたタスクは4倍の4～12件になるので、そこから期待するタスクを選別して実行する
      - 3個提案させるとテスト追加→実装→ドキュメント、みたいな順番にやるような計画が出てくるので、作業小粒に保つため最初の1個だけを実行する感じです
    - 期待: 期待するタスクが出てくる確率が上がり、多様性が増す
2. タスク実行ステップ
    - 提案されたタスクの中から期待するものをいくつかピックアップして4並列で実行
    - 全然ダメなものを弾き、他の指示で出たタスクと見比べながら、結果をレビューしてPR作成してマージ
      - 経験的に知られていることとして、「上手くやれたタスクほど大抵完了時間が短い」ので、その辺にも注目しながら採用候補を考えます
    - 期待: タスク1つあたりで品質が高いものが出てくる

というわけで、**「（目的）のために、現在のコードベースを分析して、実現するためのタスクを1～3件提案して」** を4並列で実行し、出てきたタスクの中から期待するものをまた4並列で実行する、という流れを繰り返しました。


## 振り返り

### うまくいったこと

#### 小粒CLIツールとの相性

「小粒CLIツールの開発」というテーマ選定自体が割と成功で、Codexと非常に相性が良いと感じました。
理由としては以下の点が挙げられます。

- **コマンドラインで動作が確認できる**
  - GUI操作が絡まないのは大きい
- **小さな機能単位で実装・テストが可能**
  - 対応する構文のパターンをちょっとずつ増やしていける
- **依存関係が少なくシンプル**
  - ほとんど独自実装になり標準ライブラリで済むのでライブラリ知識が不要

**結論: 小粒CLIツールはCodex開発に非常に向いている。テスト駆動で小さく回せるものだと尚良い**


#### 実質26時間でここまで行けた

実質26時間でここまで行けたのは、Codexの力もありますが、**「スキマ時間にポチポチやる」スタイルが非常にうまくいった** のが大きいです。
1日の中でまとまった時間を取るのが難しい人でも、スキマ時間にちょっとずつ進められるのは大きなメリットです。

ずっと頭の片隅で開発してるのは健康に良くないかもですが、趣味で労働密度として許されるレベルならば全然ありだと思います。
とはいえ休憩時間は取ってくださいね。


#### スキマ時間活用

指示出し部分をほとんどテンプレ化したので、スキマ時間にポチポチやるスタイルが非常にうまくいきました。
また、なにか改善を考えさせるブラック魔法の存在を知ったので、スキマ時間の活用頻度が劇的に上がりました。

とはいえ無駄にやらせるのもよくないので、1回テストと実装を回したら1～2回くらい改善タスクを走らせる、みたいなやり方にしていました。
個人的にはこれで十分でした。

**結論: スキマ時間にAIに改善タスクを投げるスタイルは非常に有効。忙しい人ほど試す価値あり**


#### 実装/テスト・ドキュメントはどこまで自動化できたか

- 実装・テスト
  - 任せたのは95%くらい
  - タスク提案から4並列で実行すれば、結果が1個以上採択できた率は100%。（記憶の限り）
    - CodexはD言語をかなり理解していて、驚くほど普通にコードを書く。
      - もちろんコンパイルエラーもあるが、諦めずに直す。
    - 特にAST操作周りは、DMDのソースも参照しつつ実装してくれるので特に指示せず書ききった。すごい。
      - ここだけ別途 [サンプル](https://github.com/lempiji/sandbox-codex-dlang/blob/main/topics/dmd_ast/source/app.d) も書かせました。
  - 毎回忘れずテスト実行して確認してくれるのはえらい。
- ドキュメント
  - 任せたのは80%くらい
  - 英語も日本語も書けはするが、実装と比べると品質は良くない印象。期待しすぎないこと。
  - 特に日本語翻訳は英語直訳で固くなることが多い。

**結論: 実装とテストは指示が固まっていればほぼ任せてOK。ドキュメントは期待しすぎない**


### うまくいかなかったこと・限界

#### 並列実行に対する疑問

並列実行は大変強力でしたが、良く言われるAIの電力消費問題のように「どこかリソースを無駄遣いしている感」から手が止まることがありました。
実装上手くいかない時は使ってみるものの、後半は基本1並列で使っていました。

機能として並列実行を付けるのは理解できるんですが、使う側としては毎回躊躇しており、冗談抜きにこれがAI倫理の一端か？と自問しています。
将来的な高度な監督スキルとして、難易度が高く重要ならば並列度を上げる、間違うことなさそうなら並列度を下げる、といった調整スキルは求められるのだろうと感じます。コスト的にも。

また、いざやってみると **「あーこれがAIガチャか」** と思いました。
頭ではわかってはいたつもりですが、実際にやってみると **開発してない感がすごい** です。
絶対やりすぎはよくない。コーディングが趣味の人は特に。

良くも悪くも、レビューが「相対的にマシなものを選ぶ作業」になるので、**絶対的な基準を見落としがちになる** のは仕事でも要注意と感じました。


**結論: 並列実行は強力だが、悩むなら並列度1で良い。あんまりやりすぎるとガチャになって、開発している実感、自己効力感が薄まるので避けたほうが良い。**


#### 「値の妥当性がよくわからない」テスト設計

話を実装に戻します。

ツールとして「2つのASTの類似度計算」をするわけですが、一見してその類似度の値が自明ではない、というのが悩みのポイントでした。
類似度計算のコアアルゴリズムは書けるけど、これで結果合ってるんだっけ？1回手で計算してみる…？みたいな話です。（しませんでしたが）

例えば「2つの関数がほぼ同じなら0.9以上」「全然違うなら0.1以下」みたいな感じで、ある程度の基準を人間が用意してあげる必要があります。
また、明確に結果が `1` のパターン（完全一致）は指示して書かせないとまったく書きませんでした。そしてここでバグが見つかりました。なんでやねん。

今回はやってませんが、こういう時は「プロパティテスト設計して書いて」で良かったのかもしれません。
次はやってみようと思います。

**結論: テスト設計はしっかり考えるべき。パターンが分かっていればコードは任せてOK**


#### アルゴリズムは任せすぎると危ない

上記類似度計算のテスト過程で、「類似度計算のアルゴリズムがいろいろおかしい」ということが判明してロジックが大幅修正になることがありました。

ツリーサイズの計算ロジックは合ってる？ASTちゃんと使えてる？みたいなところを色々細かくチェックしていく必要がありました。
最初はレビュータスク提案させて何とかしようとしたんですが、結局ちゃんとコードを読んで「ここおかしくない？」と指摘するのが一番早かったです。

**結論: アルゴリズムのレビューを任せても上手くいかない。人間が指摘する方が早いこともある**



### まとめ

今回の結論として、「Codexを使ってスキマ時間で案外ちゃんと動くツールが作れる」ということがわかりました。

こちらが成果物です。

https://github.com/lempiji/similarity-d

また、AI使った開発としてはやはり行くところまで行った感があります。

実際ツールとして結構形になってからローカルで動作確認しているのですが、それまでCodexのログで「あーなんか動いてるっぽい」という程度の感覚でした。
そこからさらに進めてほぼ完成形になると、**ほとんど自分でコード書かずに「希望するツールをもらった」という感覚が芽生えた** ので非常に新鮮に感じています。
ソフトウェアを発注して作ってもらうって元来こういう感じなんですかね？

他方懸念が大きいのは、過剰な投機的実行のコスト不安とAIガチャ感から来る自己効力感の低下です。
趣味でコーディングしている方なんかは特に注意が必要かもしれません。仕事ならまぁいいかもしれません。
趣味コードは盆栽、自分で育てるのが一番楽しいですからね。Bonsai Programmingしていきましょう！

というわけでCodexを使ったD言語のツール開発経験談でした。
もし興味があれば試してみてください。小粒にしておかないと時間が溶けること請け合いです。

以上！